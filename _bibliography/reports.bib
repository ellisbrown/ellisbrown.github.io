
@techreport{report:shek2022reprexplore,
    abbr = {CMU 16-824},
    author      = {Shek, Alvin and Brown, Ellis and Pande, Nilay and Noursi, David},
    title       = {Self-Supervised Representation Learning via Curiosity-Driven Exploration},
    institution = {Robotics Institute, Carnegie Mellon University},
    address     = {Pittsburgh, PA},
    year        = {2022},
    month       = {May},
    website     = {https://zippy-oatmeal-4b5.notion.site/Self-Supervised-Representation-Learning-via-Curiosity-Driven-Exploration-0cff22673f244cfeb6a6c3c8a0d0af37},
    abstract    = {``The performance of machine learning methods is heavily dependent on the choice of data representation'' — Bengio et al, 2012.<br>
    As machine learning continues to be applied to more complex and important tasks, this dependence on the data representation will only increase. While current machine learning methods are bottlenecked by representation quality, current methods for learning representations are bottlenecked on the dataset size. But this process of creating large static datasets, as is the mainstream practice, is expensive, time consuming, and heavily prone to human bias.<br>
    Machine learning practitioners have increasingly been focusing on paradigms such as unsupervised and self-supervised learning to help alleviate the expense of supervision in working with bigger datasets; however, these methods still suffer from the issues of static datasets. One promising approach to learn good representations without a fixed datasets is by directly interacting with the environment. The visual state space of real environments/simulators can be quite huge and intractable to explore fully. Hence, in this project, we investigate intelligent curiosity driven exploration strategies to learn good representations from a simulator using self supervised learning objectives. We discuss the effectiveness of different strategies, issues and future directions of research in this field.}
}

@techreport{report:brown2021interp,
    abbr = {CMU 16-811},
    author      = {Brown, Ellis and Roth, Aaron M.},
    title       = {Scaling Interpretable Reinforcement Learning via Decision Trees to Minecraft},
    institution = {Robotics Institute, Carnegie Mellon University},
    address     = {Pittsburgh, PA},
    year        = {2021},
    month       = {December},
    pdf         = {papers/2021_interpretable_minerl.pdf},
    abstract    = {Deep reinforcement learning is a powerful tool for learning complex control tasks; however, neural networks are notoriously “black boxes” and lack many properties desirable of autonymous systems deployed in safety critical environments. In this project, we focus on methods that result in a final control policy specified via a decision tree—which is thus interpretable and verifiable. We build upon a prior method, VIPER, that first learns a high-performing “expert” policy via any standard Deep RL technique, and then distills the expert policy into a decision tree. Our method, called MSVIPER, is specifically designed to scale to complex environements that greatly benefit from (or require) curriculum learning to be solved; we leverage the structure in the currculum stages to enable more efficient learning and a smaller (and thus more interpretable) decision tree. To demonstrate the ability of our method to succeed in complex environments, we apply it to Minecraft—a challenging open-world environment. We highlight that our method is amennable to post-training verification and modification or improvement.}
}

@techreport{report:brown2020seclending,
    abbr = {Stanford CS 361},
    author      = {Brown, Ellis},
    title       = {Securities Lending Policy Optimization},
    institution = {Department of Computer Science, Stanford University},
    address     = {Stanford, CA},
    year        = {2020},
    month       = {June},
    pdf         = {papers/2020_seclending_policy_opt.pdf},
    abstract    = {This paper presents a method to determine an optimal policy for the lending of securities by large institutions in the securities finance market as a final project for the Stanford University AA222 Engineering Design Optimization class. The securities lending process is formulated as a Markov decision process in which the lender decides whether to accept or reject incoming offers from borrowers. This formulation allows for a policy that maximizes the expected return with each decision to be derived using dynamic programming. The framework presented is easily extensible through the creation of more realistic models of the dynamics of the securities lending market.}
}

@techreport{report:brown2019uncertainty,
    abbr = {Columbia CS E6699},
    author      = {Brown*, Ellis and Manko*, Melanie and Matlin*, Ethan},
    title       = {Modeling Uncertainty in Bayesian Neural Networks with Dropout},
    institution = {Department of Electrical Engineering and Computer Science, Columbia University},
    address     = {New York, NY},
    year        = {2019},
    month       = {May},
    pdf         = {papers/2019_bnn_uncertainty.pdf},
    slides      = {presentations/2019_bnn_uncertainty_slides.pdf},
    abstract    = {While neural networks are quite successful at making predictions, these predictions are usually point estimates lacking any notion of uncertainty. However, when fed data very different from its training data, it is useful for a neural network to realize that its predictions could very well be wrong and encode that information through uncertainty bands around its point estimate prediction. Bayesian Neural Networks trained with Dropout are a natural way of modeling this uncertainty with theoretical foundations relating them to Variational Inference approximating Gaussian Process posteriors. In this paper, we investigate the effects of weight prior selection and network architecture on uncertainty estimates derived from Dropout Bayesian Neural Networks.}
}
