<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Ellis Brown </title> <meta name="author" content="Ellis L. Brown II"> <meta name="description" content=""> <meta name="keywords" content="self-supervised learning, representation learning, multimodal, vision-language, generalization, curiosity, deep learning, computer vision, machine learning, artificial intelligence"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8C%B4&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ellisbrown.github.io//"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">research </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <article> <div class="profile center justify-content-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/elb-800.webp 800w,/assets/img/elb-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="/assets/img/elb.jpg" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="elb.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="header" style="margin-bottom: 1rem;"> Ellis Brown <div class="address" style="font-size: large;"> <p>ellis.brown at nyu dot edu</p> </div> <div class="contact-icons"> <a href="https://scholar.google.com/citations?user=Hp5uEnUAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/ellisbrown" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/ellislbrownii" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/_ellisbrown" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note"> </div> </div> </div> <div class="clearfix"> <p>I am a CS PhD Student at <a href="https://cs.nyu.edu/" rel="external nofollow noopener" target="_blank">NYU Courant</a> advised by <a href="https://www.sainingxie.com/" rel="external nofollow noopener" target="_blank">Saining Xie</a> and <a href="https://cs.nyu.edu/~fergus" rel="external nofollow noopener" target="_blank">Rob Fergus</a>, and am supported by the NDSEG Fellowship. This summer, I am interning with <a href="https://www.rossgirshick.info/" rel="external nofollow noopener" target="_blank">Ross Girshick</a> in the <a href="https://prior.allenai.org/" rel="external nofollow noopener" target="_blank">PRIOR</a> team at the <a href="https://allenai.org/" rel="external nofollow noopener" target="_blank">Allen Institute for AI</a>.</p> <p>I recently graduated from a Master’s at <a href="https://www.cmu.edu/" rel="external nofollow noopener" target="_blank">CMU</a> where I was advised by <a href="http://www.cs.cmu.edu/~dpathak/" rel="external nofollow noopener" target="_blank">Deepak Pathak</a> and <a href="http://www.cs.berkeley.edu/~efros/" rel="external nofollow noopener" target="_blank">Alyosha Efros</a>. Before that, I was a founding research engineer at <a href="http://www.blackrock.com/ai" rel="external nofollow noopener" target="_blank">BlackRock AI Labs</a>, where I was fortunate to work with <a href="http://mykel.kochenderfer.com/" rel="external nofollow noopener" target="_blank">Mykel Kochenderfer</a>, <a href="http://web.stanford.edu/~boyd/" rel="external nofollow noopener" target="_blank">Stephen Boyd</a>, and <a href="http://web.stanford.edu/~hastie/" rel="external nofollow noopener" target="_blank">Trevor Hastie</a> on applied research &amp; finance. I earned Bachelors degrees in CS &amp; Math from <a href="http://www.vanderbilt.edu" rel="external nofollow noopener" target="_blank">Vanderbilt University</a>, where I worked on CoCoSci &amp; Vision with <a href="http://my.vanderbilt.edu/mkunda/" rel="external nofollow noopener" target="_blank">Maithilee Kunda</a>. I’m originally from St. Louis, MO.</p> <p>I am a proud member of the <a href="http://www.osagenation-nsn.gov/" rel="external nofollow noopener" target="_blank">Osage Nation</a> and have recently enjoyed engaging with the Native research community at <a href="http://conference.aises.org/" rel="external nofollow noopener" target="_blank">AISES</a>.</p> <p>If you haven’t made time for a regular checkin with a doctor recently, <em><a href="/blog/2020/make-time-for-the-doctor/">please do!</a></em> Even if you feel perfectly healthy.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 15vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 10%">Mar., 2024</th> <td> Thrilled to have been awarded the <a href="https://ndseg.org/" rel="external nofollow noopener" target="_blank">NDSEG Fellowship</a> to support my PhD research at NYU! </td> </tr> <tr> <th scope="row" style="width: 10%">Feb., 2024</th> <td> I will be joining <a href="https://allenai.org/" rel="external nofollow noopener" target="_blank">AllenAI (AI2)</a> as a Resesarch Intern this summer in Seattle, working with <a href="https://www.rossgirshick.info/" rel="external nofollow noopener" target="_blank">Ross Girshick</a>! </td> </tr> <tr> <th scope="row" style="width: 10%">Aug., 2023</th> <td> Excited to be starting my PhD at <a href="https://wp.nyu.edu/cilvr/" rel="external nofollow noopener" target="_blank">NYU</a> advised by <a href="https://www.sainingxie.com/" rel="external nofollow noopener" target="_blank">Saining Xie</a> and <a href="https://cs.nyu.edu/~fergus/" rel="external nofollow noopener" target="_blank">Rob Fergus</a> 🎉🗽 </td> </tr> <tr> <th scope="row" style="width: 10%">May., 2023</th> <td> Defended my <a href="https://youtu.be/haT48f2TPxs" rel="external nofollow noopener" target="_blank">Master’s thesis</a> and graduated from CMU! </td> </tr> <tr> <th scope="row" style="width: 10%">Apr., 2023</th> <td> Our paper <a href="https://internet-explorer-ssl.github.io/" rel="external nofollow noopener" target="_blank">Internet Explorer</a> was accepted to <a href="https://icml.cc/virtual/2023/index.html" rel="external nofollow noopener" target="_blank">ICML 2023</a>!! See you in Hawaii 🌺🏝😎 </td> </tr> <tr> <th scope="row" style="width: 10%">Jan., 2022</th> <td> Joined <a href="http://www.cs.cmu.edu/~dpathak/" rel="external nofollow noopener" target="_blank">Deepak Pathak’s group</a> in CMU’s Robotics Institute, and will focus on self-supervised learning and curiosity-driven exploration in computer vision. </td> </tr> <tr> <th scope="row" style="width: 10%">Aug., 2021</th> <td> Awarded the <a href="https://www.aises.org/scholarships/intel-growing-legacy-scholarship-2022-2023" rel="external nofollow noopener" target="_blank">Intel Growing The Legacy Scholarship</a> and accepted into the <a href="https://www.aises.org/content/lighting-pathway" rel="external nofollow noopener" target="_blank">Lighting the Pathway to Faculty Careers</a> program through <a href="https://www.aises.org/about" rel="external nofollow noopener" target="_blank">AISES</a>. Accepted into <a href="https://research.google/" rel="external nofollow noopener" target="_blank">Google Research</a>’s <a href="https://research.google/outreach/csrmp/" rel="external nofollow noopener" target="_blank">Computer Science Mentorship Program</a>. </td> </tr> <tr> <th scope="row" style="width: 10%">Jul., 2021</th> <td> Left <a href="https://www.blackrock.com/corporate/ai" rel="external nofollow noopener" target="_blank">BlackRock AI Labs</a> to pursue a Master’s degree in Computer Science at CMU. Bittersweet! </td> </tr> </table> </div> </div> <div class="publications"> <h2>selected research <a href="/research">(more)</a> </h2> <p></p> <p>I’m interested in self-supervised learning, representation learning, curiosity-based exploration, and leveraging internet-scale models and data. I am keen to draw inspiration from intelligence in humans and nature—especially as a goal-post rather than a blueprint. My long-term goal is to develop intelligent agents that can <em>generalize</em> and <em>continually adapt</em> as robustly and efficiently as humans do, allowing them to be <em>safely</em> deployed in the real world.</p> <h4>publications</h4> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/virl.webp" sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/virl.webp" class="preview z-depth-1 rounded" width="100%" height="auto" alt="virl.webp" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="yang2024virl" class="col-sm-8"> <div class="title">V-IRL: Grounding Virtual Intelligence in Real Life</div> <div class="author"> <a href="https://jihanyang.github.io/" rel="external nofollow noopener" target="_blank">Jihan Yang</a> ,  Runyu Ding ,  <em>Ellis Brown</em> ,  Xiaojuan Qi ,  and  <a href="https://www.sainingxie.com/" rel="external nofollow noopener" target="_blank">Saining Xie</a> </div> <div class="periodical"> <em>arXiv preprint arXiv:2402.03310</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2402.03310" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://virl-platform.github.io/static/V-IRL.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/VIRL-Platform/VIRL" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://virl-platform.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>There is a sensory gulf between the Earth that humans inhabit and the digital realms in which modern AI agents are created. To develop AI agents that can sense, think, and act as ﬂexibly as humans in real-world settings, it is imperative to bridge the realism gap between the digital and physical worlds. How can we embody agents in an environment as rich and diverse as the one we inhabit, without the constraints imposed by real hardware and control? Towards this end, we introduce V-IRL: a platform that enables agents to scalably interact with the real world in a virtual yet realistic environment. Our platform serves as a playground for developing agents that can accomplish various practical tasks and as a vast testbed for measuring progress in capabilities spanning perception, decision-making, and interaction with real-world data across the entire globe.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">yang2024virl</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yang, Jihan and Ding, Runyu and Brown, Ellis and Qi, Xiaojuan and Xie, Saining}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{V-IRL: Grounding Virtual Intelligence in Real Life}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2402.03310}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/diffusion_classifier-800.webp 800w,/assets/img/publication_preview/diffusion_classifier-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/diffusion_classifier.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="diffusion_classifier.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="li2023diffusion" class="col-sm-8"> <div class="title">Your Diffusion Model is Secretly a Zero-Shot Classifier</div> <div class="author"> <a href="https://alexanderli.com" rel="external nofollow noopener" target="_blank">Alexander C. Li</a> ,  <a href="https://mihirp1998.github.io/" rel="external nofollow noopener" target="_blank">Mihir Prabhudesai</a> ,  <a href="https://shivamduggal4.github.io/" rel="external nofollow noopener" target="_blank">Shivam Duggal</a> ,  <em>Ellis Brown</em> ,  and  <a href="https://www.cs.cmu.edu/~dpathak" rel="external nofollow noopener" target="_blank">Deepak Pathak</a> </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2303.16203" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://diffusion-classifier.github.io/static/docs/DiffusionClassifier.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://diffusion-classifier.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>The recent wave of large-scale text-to-image diffusion models has dramatically increased our text-based image generation abilities. These models can generate realistic images for a staggering variety of prompts and exhibit impressive compositional generalization abilities. Almost all use cases thus far have solely focused on sampling; however, diffusion models can also provide conditional density estimates, which are useful for tasks beyond image generation. <br><br> In this paper, we show that the density estimates from large-scale text-to-image diffusion models like Stable Diffusion can be leveraged to perform zero-shot classification without any additional training. Our generative approach to classification, which we call Diffusion Classifier, attains strong results on a variety of benchmarks and outperforms alternative methods of extracting knowledge from diffusion models. Although a gap remains between generative and discriminative approaches on zero-shot recognition tasks, our diffusion-based approach has significantly stronger multimodal compositional reasoning ability than competing discriminative approaches. <br><br> Finally, we use Diffusion Classifier to extract standard classifiers from class-conditional diffusion models trained on ImageNet. Our models achieve strong classification performance using only weak augmentations and exhibit qualitatively better "effective robustness" to distribution shift. Overall, our results are a step toward using generative over discriminative models for downstream tasks.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">li2023diffusion</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Your Diffusion Model is Secretly a Zero-Shot Classifier}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Alexander C. and Prabhudesai, Mihir and Duggal, Shivam and Brown, Ellis and Pathak, Deepak}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2206-2217}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/internet_explorer-800.webp 800w,/assets/img/publication_preview/internet_explorer-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/internet_explorer.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="internet_explorer.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="li2023internet" class="col-sm-8"> <div class="title">Internet Explorer: Targeted Representation Learning on the Open Web</div> <div class="author"> <a href="https://alexanderli.com" rel="external nofollow noopener" target="_blank">Alexander C. Li*</a> ,  <em>Ellis Brown*</em> ,  <a href="https://www.cs.berkeley.edu/~efros/" rel="external nofollow noopener" target="_blank">Alexei A. Efros</a> ,  and  <a href="https://www.cs.cmu.edu/~dpathak" rel="external nofollow noopener" target="_blank">Deepak Pathak</a> </div> <div class="periodical"> <em>In International Conference on Machine Learning</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2302.14051" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://internet-explorer-ssl.github.io/static/docs/InternetExplorer.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://internet-explorer-ssl.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Vision models heavily rely on fine-tuning general-purpose models pre-trained on large, static datasets. These general-purpose models only understand knowledge within their pre-training datasets, which are tiny, out-of-date snapshots of the Internet—where billions of images are uploaded each day. We suggest an alternate approach: rather than hoping our static datasets transfer to our desired tasks after large-scale pre-training, we propose dynamically utilizing the Internet to quickly train a small-scale model that does extremely well on the task at hand. Our approach, called Internet Explorer, explores the web in a self-supervised manner to progressively find relevant examples that improve performance on a desired target dataset. It cycles between searching for images on the Internet with text queries, self-supervised training on downloaded images, determining which images were useful, and prioritizing what to search for next. We evaluate Internet Explorer across several datasets and show that it outperforms or matches CLIP oracle performance by using just a single GPU desktop to actively query the Internet for 30–40 hours.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">li2023internet</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Internet Explorer: Targeted Representation Learning on the Open Web}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li*, Alexander C. and Brown*, Ellis and Efros, Alexei A. and Pathak, Deepak}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <br> <h4>code</h4> <div class="repositories d-flex flex-wrap flex-lg-row flex-column justify-content-between align-items-center"> <div class="repo p-2 text-center"> <a href="https://github.com/amdegroot/ssd.pytorch" rel="external nofollow noopener" target="_blank"> <img class="repo-img-light w-100" alt="amdegroot/ssd.pytorch" src="https://github-readme-stats.vercel.app/api/pin/?username=amdegroot&amp;repo=ssd.pytorch&amp;theme=default&amp;show_owner=true"> <img class="repo-img-dark w-100" alt="amdegroot/ssd.pytorch" src="https://github-readme-stats.vercel.app/api/pin/?username=amdegroot&amp;repo=ssd.pytorch&amp;theme=dark&amp;show_owner=true"> </a> </div> <div class="repo p-2 text-center"> <a href="https://github.com/internet-explorer-ssl/internet-explorer" rel="external nofollow noopener" target="_blank"> <img class="repo-img-light w-100" alt="internet-explorer-ssl/internet-explorer" src="https://github-readme-stats.vercel.app/api/pin/?username=internet-explorer-ssl&amp;repo=internet-explorer&amp;theme=default&amp;show_owner=true"> <img class="repo-img-dark w-100" alt="internet-explorer-ssl/internet-explorer" src="https://github-readme-stats.vercel.app/api/pin/?username=internet-explorer-ssl&amp;repo=internet-explorer&amp;theme=dark&amp;show_owner=true"> </a> </div> <div class="repo p-2 text-center"> <a href="https://github.com/diffusion-classifier/diffusion-classifier" rel="external nofollow noopener" target="_blank"> <img class="repo-img-light w-100" alt="diffusion-classifier/diffusion-classifier" src="https://github-readme-stats.vercel.app/api/pin/?username=diffusion-classifier&amp;repo=diffusion-classifier&amp;theme=default&amp;show_owner=true"> <img class="repo-img-dark w-100" alt="diffusion-classifier/diffusion-classifier" src="https://github-readme-stats.vercel.app/api/pin/?username=diffusion-classifier&amp;repo=diffusion-classifier&amp;theme=dark&amp;show_owner=true"> </a> </div> <div class="repo p-2 text-center"> <a href="https://github.com/JuliaFirstOrder/PiecewiseQuadratics.jl" rel="external nofollow noopener" target="_blank"> <img class="repo-img-light w-100" alt="JuliaFirstOrder/PiecewiseQuadratics.jl" src="https://github-readme-stats.vercel.app/api/pin/?username=JuliaFirstOrder&amp;repo=PiecewiseQuadratics.jl&amp;theme=default&amp;show_owner=true"> <img class="repo-img-dark w-100" alt="JuliaFirstOrder/PiecewiseQuadratics.jl" src="https://github-readme-stats.vercel.app/api/pin/?username=JuliaFirstOrder&amp;repo=PiecewiseQuadratics.jl&amp;theme=dark&amp;show_owner=true"> </a> </div> <div class="repo p-2 text-center"> <a href="https://github.com/JuliaFirstOrder/SeparableOptimization.jl" rel="external nofollow noopener" target="_blank"> <img class="repo-img-light w-100" alt="JuliaFirstOrder/SeparableOptimization.jl" src="https://github-readme-stats.vercel.app/api/pin/?username=JuliaFirstOrder&amp;repo=SeparableOptimization.jl&amp;theme=default&amp;show_owner=true"> <img class="repo-img-dark w-100" alt="JuliaFirstOrder/SeparableOptimization.jl" src="https://github-readme-stats.vercel.app/api/pin/?username=JuliaFirstOrder&amp;repo=SeparableOptimization.jl&amp;theme=dark&amp;show_owner=true"> </a> </div> <div class="repo p-2 text-center"> <a href="https://github.com/ellisbrown/name2gender" rel="external nofollow noopener" target="_blank"> <img class="repo-img-light w-100" alt="ellisbrown/name2gender" src="https://github-readme-stats.vercel.app/api/pin/?username=ellisbrown&amp;repo=name2gender&amp;theme=default&amp;show_owner=false"> <img class="repo-img-dark w-100" alt="ellisbrown/name2gender" src="https://github-readme-stats.vercel.app/api/pin/?username=ellisbrown&amp;repo=name2gender&amp;theme=dark&amp;show_owner=false"> </a> </div> </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Ellis L. Brown II. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: June 13, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script type="text/javascript">$(function(){$('[data-toggle="tooltip"]').tooltip()});</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-00N9EWF2WT"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-00N9EWF2WT");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>