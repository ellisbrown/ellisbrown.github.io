<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://ellisbrown.github.io//feed.xml" rel="self" type="application/atom+xml"/><link href="https://ellisbrown.github.io//" rel="alternate" type="text/html" hreflang="en"/><updated>2024-06-13T18:47:58+00:00</updated><id>https://ellisbrown.github.io//feed.xml</id><title type="html">Ellis Brown</title><entry><title type="html">VNC Virtual Desktop on a Headless Server</title><link href="https://ellisbrown.github.io//blog/2022/headless-vnc/" rel="alternate" type="text/html" title="VNC Virtual Desktop on a Headless Server"/><published>2022-08-25T00:00:00+00:00</published><updated>2022-08-25T00:00:00+00:00</updated><id>https://ellisbrown.github.io//blog/2022/headless-vnc</id><content type="html" xml:base="https://ellisbrown.github.io//blog/2022/headless-vnc/"><![CDATA[<p>I recently worked on a project that required me to run a program that required a GUI to run. This was a bit of a challenge because I was working on a remote server that did not have a physical display (it was “headless”). After many hours of searching/trying, I found a solution that worked. The following are my notes on how to get it working; I hope it helps you if you are in a similar situation!</p> <blockquote> <p>Note: I have seen a few other people using programs like TeamViewer to access a remote server with a virtual desktop. I personally never got this working because it requires a physical display to be connected to the server, but it may work for you.</p> </blockquote> <h2 id="installation--setup">Installation &amp; Setup</h2> <h3 id="install-tigervnc-on-the-server">Install <a href="https://tigervnc.org/">TigerVNC</a> on the server</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt <span class="nb">install </span>tigervnc-standalone-server <span class="nt">-y</span>
</code></pre></div></div> <blockquote> <p>TigerVNC is just one of many VNC servers available. I tried several and found it to be the easiest to setup and use.</p> </blockquote> <h3 id="start-the-vnc-server">Start the VNC server</h3> <p>When you start the VNC server, you will be prompted to set a password. This password will be used to connect to the server from a client.</p> <p>You can also optionally choose to set</p> <ul> <li>a virtual display number, e.g. <code class="language-plaintext highlighter-rouge">:9</code> (default is <code class="language-plaintext highlighter-rouge">:1</code>)</li> <li>a “geometry” for the screen (e.g. <code class="language-plaintext highlighter-rouge">1920x1080</code>)</li> </ul> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># create a virtual display (#9) with a screen size of 1920x1080</span>
vncserver <span class="nt">-localhost</span> no <span class="nt">-geometry</span> 1920x1080 :9
</code></pre></div></div> <p>The final output should be something like:</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>New 'MACHINE:9 (USER)' desktop at :9 on machine MACHINE
</code></pre></div></div> <p>Once the display is created, you can connect to it using a VNC client.</p> <h2 id="headless-linux-desktop-environment">Headless Linux Desktop Environment</h2> <p>If you are connecting to a Linux server without a physical display, you will need to install a dummy XServer for the VNC server to use.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt <span class="nb">install </span>xterm xserver-xorg-video-dummy
</code></pre></div></div> <h2 id="viewing-the-vnc-display">Viewing the VNC display</h2> <p>To view the VNC display, you will need a VNC client. There are many available, select the one that works best for you. I personally use the built in one on Mac. Instructions below:</p> <h3 id="mac-vnc-viewer">Mac VNC Viewer</h3> <p>You need to forward the port of the VNC server (<code class="language-plaintext highlighter-rouge">5909</code> above) to your local machine over SSH, and have a stable connection open. Then you can open the viewer with:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>open vnc://localhost:5909
</code></pre></div></div> <blockquote> <p>Note: the port number is <code class="language-plaintext highlighter-rouge">5900+N</code> where <code class="language-plaintext highlighter-rouge">N</code> is the display number you chose when starting the VNC server.</p> </blockquote> <h2 id="programmatic-access-to-the-virtual-display">Programmatic Access to the Virtual Display</h2> <p>In order for programs to access the virtual display, you need to set the <code class="language-plaintext highlighter-rouge">DISPLAY</code> environment variable to the virtual display number (e.g. <code class="language-plaintext highlighter-rouge">:9</code>).</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">DISPLAY</span><span class="o">=</span>:9
</code></pre></div></div> <p>With this set, you can run code that requires a display (e.g. <code class="language-plaintext highlighter-rouge">matplotlib</code>, <code class="language-plaintext highlighter-rouge">ai2thor</code>, etc.) without ever needing to physically interact with the server/machine. Super useful for working on the cloud!</p> <blockquote> <p>Note: Within your code itself, you may also need to set the <code class="language-plaintext highlighter-rouge">DISPLAY</code> environment variable to the corresponding display number to get it to run correctly (e.g., in Python: <code class="language-plaintext highlighter-rouge">os.environ['DISPLAY'] = ':9'</code>).</p> </blockquote> <h2 id="troubleshooting--tips">Troubleshooting / Tips</h2> <p>Fixing issues with the virtual screen</p> <h3 id="status-of-all-vnc-displays">Status of all VNC displays</h3> <p>You can check the status of the VNC server and all virtual displays with:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vncserver <span class="nt">-list</span>
</code></pre></div></div> <p>The following is an example of the output with a stale screen:</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TigerVNC server sessions:

X DISPLAY #	PROCESS ID
:9	30309 (stale)
</code></pre></div></div> <h3 id="kill-the-virtual-display">Kill the virtual display</h3> <p>If the virtual display is stale, you can kill it with:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vncserver <span class="nt">-kill</span> :9
</code></pre></div></div> <h3 id="change-the-password">Change the password</h3> <p>If you need to change the password, run:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vncpasswd
</code></pre></div></div> <h2 id="references">References</h2> <ul> <li><a href="https://www.sproutworkshop.com/2021/04/how-to-create-a-virtual-headless-tigervnc-server-on-ubuntu-20-04/">https://www.sproutworkshop.com/2021/04/how-to-create-a-virtual-headless-tigervnc-server-on-ubuntu-20-04/</a></li> </ul>]]></content><author><name></name></author><category term="programming"/><category term="vnc"/><category term="engineering"/><summary type="html"><![CDATA[Setup a virtual desktop environment on a Linux server without a monitor.]]></summary></entry><entry><title type="html">Creating a Private Fork of a GitHub Repository</title><link href="https://ellisbrown.github.io//blog/2022/git-private-forks/" rel="alternate" type="text/html" title="Creating a Private Fork of a GitHub Repository"/><published>2022-04-08T00:00:00+00:00</published><updated>2022-04-08T00:00:00+00:00</updated><id>https://ellisbrown.github.io//blog/2022/git-private-forks</id><content type="html" xml:base="https://ellisbrown.github.io//blog/2022/git-private-forks/"><![CDATA[<p>I have found myself forking repositories quite frequently recently for school projects and research, and most of the time I have wanted to keep them private on GitHub. It is not that straightforward, so once I figured out the right way to accomplish it I started honing this post to remind myself of the right steps. Hopefully it helps any one else trying to accomplish the same thing!</p> <h2 id="basic-steps">Basic Steps</h2> <ol> <li> <p>Create a new <a href="https://help.github.com/articles/creating-a-new-repository/">private repository on Github</a> <img src="/assets/posts/programming/private-repo.png" style="max-width:600px; margin: 0 auto; display: block;"/></p> </li> <li> <p>Fork the repo (<code class="language-plaintext highlighter-rouge">BASE_REPO</code>) to your new private repo (<code class="language-plaintext highlighter-rouge">PRIVATE_REPO</code>) as follows:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">BASE_REPO_URL</span><span class="o">=</span>&lt;BASE&gt;  <span class="c"># remote URL of repo you are forking</span>
<span class="nv">PRIVATE_REPO_URL</span><span class="o">=</span>&lt;PRIVATE&gt;  <span class="c"># remote URL of your new private fork repo</span>

<span class="c"># Create a bare clone of the base repo</span>
git clone <span class="nt">--bare</span> <span class="nv">$BASE_REPO_URL</span>

<span class="c"># Mirror-push your bare clone to your new private repo</span>
<span class="nb">cd</span> <span class="k">${</span><span class="nv">BASE_REPO_URL</span><span class="p">##*/</span><span class="k">}</span>
git push <span class="nt">--mirror</span> <span class="nv">$PRIVATE_REPO_URL</span>

<span class="c"># Remove the temporary local repository you created in step 2</span>
<span class="nb">cd</span> ..
<span class="nb">rm</span> <span class="nt">-rf</span> <span class="k">${</span><span class="nv">BASE_REPO_URL</span><span class="p">##*/</span><span class="k">}</span>
</code></pre></div> </div> </li> </ol> <hr/> <h2 id="recommended-additional-steps">Recommended Additional Steps</h2> <p><code class="language-plaintext highlighter-rouge">cd</code> to your preferred workspace, then clone your private fork</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone <span class="nv">$PRIVATE_REPO_URL</span>  <span class="c"># clone the private fork</span>
<span class="nb">cd</span> <span class="k">${${</span><span class="nv">PRIVATE_REPO_URL</span><span class="p">##*/</span><span class="k">}</span><span class="p">%%.git</span><span class="k">}</span>  <span class="c"># cd into the cloned directory</span>

<span class="c"># add the original repo as remote to fetch (potential) future changes.</span>
git remote add upstream <span class="nv">$BASE_REPO_URL</span>

<span class="c"># disable push on the remote (as you are not allowed to push to it anyway).</span>
git remote set-url <span class="nt">--push</span> upstream DISABLE
</code></pre></div></div> <ul> <li> <p>You can list all your remotes with <code class="language-plaintext highlighter-rouge">git remote -v</code>. You should see:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>origin	&lt;PRIVATE_REPO_URL&gt; (fetch)
origin	&lt;PRIVATE_REPO_URL&gt; (push)
upstream	&lt;BASE_REPO_URL&gt; (fetch)
upstream	DISABLE (push)
</code></pre></div> </div> </li> <li> <p>When you push, do so on <code class="language-plaintext highlighter-rouge">origin</code> with <code class="language-plaintext highlighter-rouge">git push origin</code>.</p> </li> <li> <p>When you want to pull changes from <code class="language-plaintext highlighter-rouge">upstream</code> you can just fetch the remote and rebase on top of your work.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  git fetch upstream
  git rebase upstream/main
</code></pre></div> </div> </li> </ul> <table> <tbody> <tr> <td><strong><em>Note:</em></strong> <code class="language-plaintext highlighter-rouge">##*/</code> and <code class="language-plaintext highlighter-rouge">%%.git</code> are some bash <a href="https://www.linuxjournal.com/article/8919">variable mangling</a> to extract everything after the last <code class="language-plaintext highlighter-rouge">/</code> in the URL and before the <code class="language-plaintext highlighter-rouge">.git</code> respectively.</td> </tr> </tbody> </table> <p>Additional information on creating a private fork by duplicating a repo is documented <a href="https://help.github.com/articles/duplicating-a-repository/">here</a>.</p>]]></content><author><name></name></author><category term="programming"/><category term="git"/><category term="engineering"/><summary type="html"><![CDATA[Simple steps commands to create a private fork of a GitHub repository.]]></summary></entry><entry><title type="html">Open-source Julia packages for first-order optimization</title><link href="https://ellisbrown.github.io//blog/2021/julia-first-order/" rel="alternate" type="text/html" title="Open-source Julia packages for first-order optimization"/><published>2021-07-31T00:00:00+00:00</published><updated>2021-07-31T00:00:00+00:00</updated><id>https://ellisbrown.github.io//blog/2021/julia-first-order</id><content type="html" xml:base="https://ellisbrown.github.io//blog/2021/julia-first-order/"><![CDATA[<blockquote> <p><em>This was originally posted <a href="https://medium.com/blackrock-engineering/open-source-julia-packages-for-first-order-optimization-ac51f0f1aa09">here</a> on BlackRock’s engineering blog.</em></p> </blockquote> <p>In this post, we present two Julia packages that the BlackRock AI Labs has released, <a href="https://github.com/JuliaFirstOrder/PiecewiseQuadratics.jl">PiecewiseQuadratics.jl</a> and <a href="https://github.com/JuliaFirstOrder/SeparableOptimization.jl">SeparableOptimization.jl</a>, along with a new Julia organization we created that is dedicated to first-order optimization methods. We originally developed these packages and the corresponding methodology to solve a class of portfolio construction problems, which we detail in a <a href="https://arxiv.org/abs/2103.05455">paper</a> published in March. We will feature this work in a talk at the <a href="https://juliacon.org/2021/">JuliaCon 2021</a> <a href="https://jump.dev/meetings/juliacon2021/">JuMP-dev workshop</a> later this month!</p> <p><em>See also: another implementation of these packages in Rust, as described in <a href="https://medium.com/blackrock-engineering/writing-an-optimization-library-in-rust-588628c0e500">this blog post</a>.</em></p> <h2 id="why-julia">Why Julia?</h2> <p>After devising the ADMM based optimization methodology described in the <a href="https://arxiv.org/abs/2103.05455">paper</a>, there was no question what language we would use to implement it. Julia’s unparalleled combination of an elegant and expressive high-level syntax with C/Fortran level speed allowed us to quickly translate our formulations into efficient code. We are excited to share it with the growing Julia optimization community!</p> <h2 id="piecewisequadraticsjl"><a href="https://github.com/JuliaFirstOrder/PiecewiseQuadratics.jl">PiecewiseQuadratics.jl</a></h2> <p>This package allows for the representation and manipulation of univariate piecewise quadratic functions, designed to be used as a cost function in optimization packages. Piecewise quadratic functions are composed of several equations (“pieces”), each of which takes the standard quadratic form and applies to a different part of the domain. Consider the following example:</p> \[f(x) = \left\{\begin{array}{ll} x^2 - 3x - 3 &amp; \text{if } x \in [-\infty, 3]\\ x + 3 &amp; \text{if } x \in [3, 4]\\ 2x^2 - 20x + 47 &amp; \text{if } x \in [4, 6]\\ x - 7 &amp; \text{if } x \in [6, 7.5]\\ 4x - 29 &amp; \text{if } x \in [7.5, \infty]\\ \end{array}\right.\] <p>Within <a href="https://github.com/JuliaFirstOrder/PiecewiseQuadratics.jl">PiecewiseQuadratics.jl</a>, we would represent <code class="language-plaintext highlighter-rouge">f</code> as a <code class="language-plaintext highlighter-rouge">PiecewiseQuadratic</code>, which is simply a list of <code class="language-plaintext highlighter-rouge">BoundedQuadratics</code>. Here, each <code class="language-plaintext highlighter-rouge">BoundedQuadratic</code> represents our quadratic equation “pieces,” and is defined by the equation’s <code class="language-plaintext highlighter-rouge">p</code>, <code class="language-plaintext highlighter-rouge">q</code>, and <code class="language-plaintext highlighter-rouge">r</code> terms along with the <code class="language-plaintext highlighter-rouge">Interval</code> it applies to (represented by <code class="language-plaintext highlighter-rouge">[lb, ub]</code>). Altogether, we represent f with the following code:</p> <div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">f</span> <span class="o">=</span> <span class="n">PiecewiseQuadratic</span><span class="x">([</span>
    <span class="c"># BoundedQuadratic(lb, ub, p, q, r),</span>
    <span class="n">BoundedQuadratic</span><span class="x">(</span><span class="o">-</span><span class="nb">Inf</span><span class="x">,</span> <span class="mf">3.0</span><span class="x">,</span> <span class="mf">1.0</span><span class="x">,</span> <span class="o">-</span><span class="mf">3.0</span><span class="x">,</span> <span class="mf">3.0</span><span class="x">),</span>
    <span class="n">BoundedQuadratic</span><span class="x">(</span><span class="mf">3.0</span><span class="x">,</span> <span class="mf">4.0</span><span class="x">,</span> <span class="mf">0.0</span><span class="x">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="x">,</span> <span class="mf">3.0</span><span class="x">),</span>
    <span class="n">BoundedQuadratic</span><span class="x">(</span><span class="mf">4.0</span><span class="x">,</span> <span class="mf">6.0</span><span class="x">,</span> <span class="mf">2.0</span><span class="x">,</span> <span class="o">-</span><span class="mf">20.0</span><span class="x">,</span> <span class="mf">47.0</span><span class="x">),</span>
    <span class="n">BoundedQuadratic</span><span class="x">(</span><span class="mf">6.0</span><span class="x">,</span> <span class="mf">7.5</span><span class="x">,</span> <span class="mf">0.0</span><span class="x">,</span> <span class="mf">1.0</span><span class="x">,</span> <span class="o">-</span><span class="mf">7.0</span><span class="x">),</span>
    <span class="n">BoundedQuadratic</span><span class="x">(</span><span class="mf">7.5</span><span class="x">,</span> <span class="nb">Inf</span><span class="x">,</span> <span class="mf">0.0</span><span class="x">,</span> <span class="mf">4.0</span><span class="x">,</span> <span class="o">-</span><span class="mf">29.0</span><span class="x">)</span>
<span class="x">])</span>
</code></pre></div></div> <p><strong><em>Note:</em></strong> <em>although this function is complete over the domain, this is not a requirement! Functions default to <code class="language-plaintext highlighter-rouge">Inf</code> when evaluated on undefined segments.</em></p> <p>We implement several methods that are useful for optimization — such as the <code class="language-plaintext highlighter-rouge">sum</code>, the <code class="language-plaintext highlighter-rouge">derivative</code>, the convex <code class="language-plaintext highlighter-rouge">envelope</code>, and the <code class="language-plaintext highlighter-rouge">prox</code> operator — as well as several utility methods. Below we visualize the function <code class="language-plaintext highlighter-rouge">f</code> that we previously defined along with its convex envelope using <code class="language-plaintext highlighter-rouge">get_plot</code> (which allows interfacing with your favorite Julia plotting library) and <a href="http://juliaplots.org/">JuliaPlots</a>:</p> <div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">using</span> <span class="n">Plots</span>
<span class="n">plot</span><span class="x">(</span><span class="n">get_plot</span><span class="x">(</span><span class="n">f</span><span class="x">);</span> <span class="n">label</span><span class="o">=</span><span class="s">"piece-wise quadratic"</span><span class="x">,</span> <span class="n">grid</span><span class="o">=</span><span class="nb">false</span><span class="x">,</span> <span class="n">color</span><span class="o">=:</span><span class="n">black</span><span class="x">)</span>
<span class="n">plot!</span><span class="x">(</span><span class="n">get_plot</span><span class="x">(</span><span class="n">simplify</span><span class="x">(</span><span class="n">envelope</span><span class="x">(</span><span class="n">f</span><span class="x">)));</span> <span class="n">label</span><span class="o">=</span><span class="s">"envelope"</span><span class="x">,</span> <span class="n">linestyle</span><span class="o">=:</span><span class="n">dash</span><span class="x">,</span> <span class="n">color</span><span class="o">=:</span><span class="n">blue</span><span class="x">,</span> <span class="n">la</span><span class="o">=</span><span class="mf">0.5</span><span class="x">)</span>
</code></pre></div></div> <p><img src="/assets/posts/julia/pwq.png" alt=""/></p> <p>See the <a href="https://juliafirstorder.github.io/PiecewiseQuadratics.jl/stable/">PiecewiseQuadratics.jl documentation</a> for details and more examples of the package!</p> <h2 id="separableoptimizationjl">SeparableOptimization.jl</h2> <p>This package uses a derivative of <a href="https://stanford.edu/~boyd/admm.html">ADMM</a> to solve Linearly Constrained Separable Optimization (LCSO) problems. LCSO problems have cost functions that are separable over the decision variable and have linear constraints. In our portfolio construction example, the decision variable is a vector, where the entries are the percent of our total portfolio value in each of assets; we require that these values sum to (a linear constraint) and add in cost functions that are specific to each asset (they separate over our decision variable). These costs could be anything from a cost to hold each asset (e.g., the cost to short TSLA is higher than for MSFT), to position limits per asset (e.g., requiring 10–20% of our portfolio value is in BTC), to combinations of various other costs. Often these functions are very complicated — we represent them using <a href="https://github.com/JuliaFirstOrder/PiecewiseQuadratics.jl">PiecewiseQuadratics.jl</a>!</p> <p>LCSO problems are a very general formulation and have wide application beyond portfolio optimization. Other applications might include radiation treatment planning — where we optimize the radiation intensity pattern for cancer treatment — or dynamic energy management — where we optimize the power usage of a network of devices over time.</p> <p>See the <a href="https://arxiv.org/abs/2103.05455">paper</a> for more information on LCSO problems and our portfolio construction example, and the <a href="https://juliafirstorder.github.io/SeparableOptimization.jl/dev/">SeparableOptimization.jl documentation</a> for details and examples of the package!</p> <h2 id="a-new-julia-organization">A new Julia organization</h2> <p>In the process of open sourcing these packages, we thought a lot about how to maximize their impact and usage. Julia’s open-source community often organizes around <a href="https://julialang.org/community/organizations/">GitHub Organizations</a>.</p> <blockquote> <p>“This allows for a higher degree of collaboration and structure that ultimately enables each of these communities to be self-sustaining.”</p> </blockquote> <p>Rather than hosting these packages on <a href="https://github.com/blackrock/">BlackRock’s GitHub</a>, we wanted to find an organization to host them alongside other related packages that would be of mutual benefit. After discussion with various organizations, we realized that there were a few related packages out there, but no organization dedicated to first-order optimization methods. So, we decided to create <a href="https://github.com/JuliaFirstOrder">JuliaFirstOrder</a>. We currently have five packages and are actively working to cultivate the community. A special thank you to <a href="https://mlubin.github.io/">Miles Lubin</a> for sparking the idea and making the right introductions!</p> <h2 id="conclusions">Conclusions</h2> <p>We are very excited to get these new packages into the hands of the Julia community, and to grow our new organization. Head to their documentation pages to learn more and how to give them a try. Don’t forget to tune into our <a href="https://youtu.be/9iXWtqm60sQ?si=APdRf8lwlpAPf6-x">presentation at JuliaCon 2021</a> titled “Linearly Constrained Separable Optimization!”</p>]]></content><author><name></name></author><category term="optimization"/><category term="julia"/><category term="open-source"/><category term="optimization"/><summary type="html"><![CDATA[We present two Julia packages that the BlackRock AI Labs has released, PiecewiseQuadratics.jl and SeparableOptimization.jl, along with a new Julia organization we created that is dedicated to first-order optimization methods.]]></summary></entry><entry><title type="html">Make the time to go to the doctor, even if you feel perfectly healthy!</title><link href="https://ellisbrown.github.io//blog/2020/make-time-for-the-doctor/" rel="alternate" type="text/html" title="Make the time to go to the doctor, even if you feel perfectly healthy!"/><published>2020-01-23T00:00:00+00:00</published><updated>2020-01-23T00:00:00+00:00</updated><id>https://ellisbrown.github.io//blog/2020/make-time-for-the-doctor</id><content type="html" xml:base="https://ellisbrown.github.io//blog/2020/make-time-for-the-doctor/"><![CDATA[<blockquote> <p><em>I originally posted this on Instagram a little over a week ago (Jan. 2020). After hearing that dozens of people had decided to make doctors appointments after seeing my post, I was compelled to formalize the message here so that it could reach more people.</em></p> </blockquote> <p><img class="align-right col-sm mt-3 mt-md-0" src="/assets/posts/doctor/bed.jpg"/></p> <p>If you told me a year ago I would need open-heart surgery just after turning 25, I would have thought you were crazy. Just like most new college grads, I had felt healthy and invincible for as long as I could remember.</p> <p>Last spring I made an appointment with a neurologist regarding infrequent migraines I had been having. Luckily my case is nothing more than a nuisance, but something unexpected struck me from my visit: I was at a loss for words when the doctor asked me who my PCP (primary care physician) was.</p> <p>I had seen the same pediatrician since I was a kid, even over the summers while in college; in my two and a half years on my own in the real world, getting a routine checkup had not even crossed my mind. I was preoccupied with work and life in a new city. But hey, I was healthy and finding a doctor is nearly impossible when you’re working full-time. He gave me a bit of a hard time about it and pointed me to a couple of good PCPs to look up.</p> <p>Luckily I listened.</p> <p>I carved out the time and scheduled a physical with a new PCP. All the tests looked great as expected, but he remarked that I had a heart murmur (abnormal sounding heartbeat). I had known about the murmur my whole life—I’d had it checked out when I was younger and it was supposedly no big deal. The doctor said I should follow up with a cardiologist to get it checked in-depth, just to be safe.</p> <p><img class="align-left col-sm mt-3 mt-md-0" src="/assets/posts/doctor/scar.jpg"/></p> <p>A couple of weeks and a barrage of tests later, I was diagnosed with a congenital heart valve defect that was causing my aortic valve to deteriorate and my aortic root to enlarge. If I didn’t get it fixed or replaced in the next year or two, my valve could go beyond repair and I would have an aneurysm, likely before my 30s.</p> <p>In the grand scheme of things, my health scare has been relatively manageable. There are a lot of diagnoses that would have been much worse. I was lucky to find out about my condition when I did, and luckier still to have had access to such great doctors. I was able to have surgery to repair my valve and aortic root, and my heart is now healthier than ever.</p> <p>Unexpected health issues can arise in your mid-twenties, even if you <em>feel</em> perfectly fine! I know how hard it is to make time, but a couple of hours to get a checkup now could give you 60 years.</p> <p><br/></p> <blockquote> <p>If you read this and want to chat, <em>please</em> do not hestitate to reach out. I’m especially happy to hear from people who were inspired to make a doctor’s appointment after reading this—hopefully all is well, but I sure can commiserate if it isn’t. Even if you just feel like breaking the ice and acknowledging you’ve read this or asking a question about the experience, that is fine too!</p> </blockquote>]]></content><author><name></name></author><category term="life"/><summary type="html"><![CDATA[If you told me a year ago I would need open-heart surgery just after turning 25, I would have thought you were crazy. Just like most new college grads, I had felt healthy and invincible for as long as I could remember.]]></summary></entry><entry><title type="html">Gender Inference from Character Sequences in Multinational First Names</title><link href="https://ellisbrown.github.io//blog/2017/name2gender-introduction/" rel="alternate" type="text/html" title="Gender Inference from Character Sequences in Multinational First Names"/><published>2017-12-26T00:00:00+00:00</published><updated>2017-12-26T00:00:00+00:00</updated><id>https://ellisbrown.github.io//blog/2017/name2gender-introduction</id><content type="html" xml:base="https://ellisbrown.github.io//blog/2017/name2gender-introduction/"><![CDATA[<blockquote> <p><em>Note: This post has also been published on Medium <a href="https://towardsdatascience.com/name2gender-introduction-626d89378fb0">here</a>.</em></p> </blockquote> <p>Consider the names “John” and “Cindy” — most people would instantly mark John as a male name and Cindy as a female one. Is this the case <em>primarily</em> because we have seen so many examples of male Johns and female Cindys that our brains have built up a latent association between the specific name and the corresponding gender? Probably.</p> <p>But some component of the name itself (its spelling / combination of letters) contributes to the gender with which it is associated to a large degree as well. Consider the names “Andy” and “Andi.” They are phonetically identical (<a href="https://en.wiktionary.org/wiki/Andy#Pronunciation">/ˈæn.di/</a>), however most people would categorize “Andy” as male and “Andi” as female upon seeing the spellings. The suffix of a name can indicate the name’s gender; however, the rules are not cut and dry. For example, names “ending in <em>-yn</em> appear to be predominantly female, despite the fact that names ending in <em>-n</em> tend to be male; and names ending in <em>-ch</em> are usually male, even though names that end in <em>-h</em> tend to be female.” <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> There are many more character patterns that correspond to a certain gender classification than just the suffix — this task is not trivial.</p> <p>The gender classification of a name becomes increasingly difficult when you consider the space of all names from around the world — the examples I have given thus far are admittedly from a standard American viewpoint. Let’s now consider two Indian names (a culture with which I have next to no exposure): when I see the names “Priyanka” and “Srikanth,” I instantly assume Priyanka to be female and Srikanth to be male. Why is that? How do our brains extract the gender revealing information encoded in the sequence of characters that compose a name?</p> <h1 id="who-cares">Who cares?</h1> <p>Accurate prediction of an unknown individual’s gender is desirable for use in marketing, social science, and many other applications in academia and industry. Perhaps the most obvious and telling indicator of a person’s gender is their first name. Most previous work in classifying gender via first name has concerned using a large corpus of known names to give a probabilistic prediction on the names that are known. This post attempts to explore the space of names that are <em>unknown</em> by examining the facets of a first name — specifically focusing on the sequences of characters within the name — that contain non-trivial gender-revealing information. It is also an exercise in applying ML/DL to real problems.</p> <p>This gender classification problem is similar to but fundamentally different from a larger class of problem in <a href="https://en.wikipedia.org/wiki/Natural_language_understanding">Natural Language Understanding</a>. Given the words “cat” and “dog,” almost all people will assign cat to female and dog to male.</p> <figure class="align-left"> <img src="/assets/posts/name2gen/dog.jpg" alt="Dog"/> <figcaption><a href="https://goo.gl/YZPEjm">source</a></figcaption> </figure> <p>The core difference here is that when we read the word “dog,” our brains translate the sequence of characters “d-o-g” to a high dimensional representation of the abstract entity that is our understanding of a dog. It is some combination of features in this high dimensional representation in our brains that correlate more closely to our abstract representation of <em>males</em> than to that of <em>females</em>; it is not the sequence of characters themselves that contain the gender-revealing information (at least for the most part).</p> <p>Our gender classification problem becomes even more interesting when you abstract it from names to <em>all</em> words in general. Linguistically, many languages are structured with the concept of a <a href="https://en.wikipedia.org/wiki/Grammatical_gender">grammatical gender</a> wherein classes of nouns in the language are formally associated with one of a discrete set of genders.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup> In such languages, certain sequences of characters in a word can almost surely identify the grammatical gender of the word. Learning these character sequences — whether explicitly or implicitly — is an inherent part of learning the language. Furthermore, understanding of such character patterns may assist in understanding of unseen words. For these reasons, studying information embedded in character sequences seems like an interesting and integral topic to Linguistics and NLU that is beyond the scope of this post.</p> <hr/> <h1 id="methodology">Methodology</h1> <p>All code for this project is available at</p> <div class="repositories d-flex flex-wrap flex-md-row flex-column justify-content-between align-items-center"> <div class="repo p-2 text-center"> <a href="https://github.com/ellisbrown/name2gender"> <img class="repo-img-light w-100" alt="ellisbrown/name2gender" src="https://github-readme-stats.vercel.app/api/pin/?username=ellisbrown&amp;repo=name2gender&amp;theme=default&amp;show_owner=false"/> <img class="repo-img-dark w-100" alt="ellisbrown/name2gender" src="https://github-readme-stats.vercel.app/api/pin/?username=ellisbrown&amp;repo=name2gender&amp;theme=dark&amp;show_owner=false"/> </a> </div> </div> <p><br/></p> <h2 id="naïve-bayes">Naïve-Bayes</h2> <p>As an initial approach to the topic, I explore a vanilla machine learning technique using hard-coding features of names that are known to have high correlation to the name’s associated gender (such as suffix, as mentioned earlier). This quick and dirty implementation is actually able to achieve pretty good results with minimal work.</p> <blockquote> <p>The features in used in this approach are pulled directly from the NLTK book: Names ending in -a, -e and -i are likely to be female, while names ending in -k, -o, -r, -s and -t are likely to be male… names ending in -yn appear to be predominantly female, despite the fact that names ending in -n tend to be male; and names ending in -ch are usually male, even though names that end in -h tend to be female.<sup id="fnref:1:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup></p> </blockquote> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">gender_features</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">features</span><span class="p">[</span><span class="sh">"</span><span class="s">last_letter</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">name</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">lower</span><span class="p">()</span>
<span class="n">features</span><span class="p">[</span><span class="sh">"</span><span class="s">first_letter</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">name</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">lower</span><span class="p">()</span> <span class="c1"># names ending in -yn are mostly female, names ending in -ch are mostly male, so add 3 more features
</span><span class="n">features</span><span class="p">[</span><span class="sh">"</span><span class="s">suffix2</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">name</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span>
<span class="n">features</span><span class="p">[</span><span class="sh">"</span><span class="s">suffix3</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">name</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">:]</span>
<span class="n">features</span><span class="p">[</span><span class="sh">"</span><span class="s">suffix4</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">name</span><span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">:]</span>
<span class="k">return</span> <span class="n">features</span></code></pre></figure> <p>These features are plugged into the NLTK NaiveBayesClassifier for easy training and testing.</p> <h3 id="results">Results</h3> <p>I trained this model with a 70/30 train-test split (~95k training names, ~40.6k testing names). The testing accuracy was around <strong>85%</strong>, which is arguably pretty good for this task.</p> <p>Example code usage is available at <a href="https://github.com/ellisbrown/name2gender/blob/master/naive_bayes/demo.ipynb">naive_bayes/demo.ipynb</a>.</p> <h2 id="char-rnn">Char-RNN</h2> <p>Of course, there are many many patterns of characters in a name that might contain gender cues — especially when considering our global (worldly) name space; it seems absurd to attempt to hard code every possible pattern when we have <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Learning</a>. In this vein, I explore a Character-level Recurrent Neural Network approach using <a href="http://pytorch.org/">PyTorch</a> that attempts to learn the various gender-revealing sequences without having to explicitly specify them.</p> <h3 id="tensor-representation">Tensor Representation</h3> <p>The first step here is to figure out how to represent a name as a <a href="https://en.wikipedia.org/wiki/Tensor">tensor</a>. Since our goal is to pick up on all of the nuances in the sequences of letters that make up first names, we want to break up the name and look character by character. In order to represent each character, we create a <a href="https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f">one-hot vector</a> of size <code class="language-plaintext highlighter-rouge">&lt;1 x N_LETTERS&gt;</code> (a one-hot vector is filled with 0s except for a 1 at the index of the current letter, e.g. <code class="language-plaintext highlighter-rouge">"c" = &lt;0 0 1 0 0 ... 0&gt;</code>).</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">name_to_tensor</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
<span class="sh">"""</span><span class="s">converts a name to a vectorized numerical input for use with a nn
each character is converted to a one hot (n, 1, 26) tensor
Args:
name (string): first name (e.g., </span><span class="sh">"</span><span class="s">Ellis</span><span class="sh">"</span><span class="s">)
Return:
tensor (torch.tensor)
</span><span class="sh">"""</span>
<span class="n">name</span> <span class="o">=</span> <span class="nf">clean_str</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">FloatTensor</span> <span class="k">if</span> <span class="n">cuda</span> <span class="k">else</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span>
<span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">name</span><span class="p">),</span> <span class="n">N_LETTERS</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">tensor</span><span class="p">)</span>
<span class="k">for</span> <span class="n">li</span><span class="p">,</span> <span class="n">letter</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
<span class="n">letter_index</span> <span class="o">=</span> <span class="n">ALL_LETTERS</span><span class="p">.</span><span class="nf">find</span><span class="p">(</span><span class="n">letter</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">[</span><span class="n">li</span><span class="p">][</span><span class="n">letter_index</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">return</span> <span class="n">tensor</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">tensor_to_name</span><span class="p">(</span><span class="n">name_tensor</span><span class="p">):</span>
<span class="sh">"""</span><span class="s">converts a name tensor to a string representation of a name
Args:
tensor (torch.tensor)
Return:
name (string)
</span><span class="sh">"""</span>
<span class="n">ret</span> <span class="o">=</span> <span class="sh">""</span>
<span class="k">for</span> <span class="n">letter_tensor</span> <span class="ow">in</span> <span class="n">name_tensor</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
<span class="n">nz</span> <span class="o">=</span> <span class="n">letter_tensor</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nf">nonzero</span><span class="p">()</span>
<span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="nf">numel</span><span class="p">(</span><span class="n">nz</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
<span class="n">ret</span> <span class="o">+=</span> <span class="p">(</span><span class="n">string</span><span class="p">.</span><span class="n">ascii_lowercase</span><span class="p">[</span><span class="n">nz</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="k">return</span> <span class="n">ret</span></code></pre></figure> <h3 id="nametensor-conversion">Name/Tensor conversion</h3> <p>An alternative approach might be to store the value of a character by its location in the alphabet <code class="language-plaintext highlighter-rouge">"c" = 3</code>; however, this might cause the model to learn some patterns in the value of the character that we do not intend (e.g., it might learn that “c” is more similar to “a” than it is to “x” because they are closer alphabetically while there is actually no similarity difference).</p> <figure class="align-right" style="max-width: 200px"> <img src="/assets/posts/name2gen/rnn.png" alt="RNN" style="max-width: 100%" data-zoomable=""/> <figcaption><a href="https://goo.gl/BB7h2A">source</a></figcaption> </figure> <h3 id="model-definition">Model Definition</h3> <p>We then define the structure of the network module itself:</p> <p>Following the direction of the <a href="https://goo.gl/BB7h2A">PyTorch name nationality classification example</a>, we create a simple network with 2 <a href="http://pytorch.org/docs/master/nn.html#linear-layers">linear layers</a> operating on an input and hidden state, and a <a href="http://pytorch.org/docs/master/nn.html#logsoftmax">LogSoftmax</a> layer on the output. I use 128 hidden units.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">3</a></sup></p> <p>This is a very simple network definition, and likely could be improved by adding more linear layers or better shaping the network.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">RNN</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
<span class="sh">"""</span><span class="s">Recurrent Neural Network
original source: https://goo.gl/12wiKB
Simple implementation of an RNN with two linear layers and a LogSoftmax
layer on the output
Args:
input_size: (int) size of data
hidden_size: (int) number of hidden units
output_size: (int) size of output
</span><span class="sh">"""</span>
<span class="k">def</span> <span class="err">**</span><span class="nf">init</span><span class="o">**</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
<span class="nf">super</span><span class="p">(</span><span class="n">RNN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="o">**</span><span class="n">init</span><span class="o">**</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>

        <span class="n">self</span><span class="p">.</span><span class="n">i2h</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">input_size</span> <span class="o">+</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">i2o</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">input_size</span> <span class="o">+</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="n">combined</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="nb">input</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">hidden</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">i2h</span><span class="p">(</span><span class="n">combined</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">i2o</span><span class="p">(</span><span class="n">combined</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>

    <span class="k">def</span> <span class="nf">init_hidden</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cuda</span><span class="p">:</span>
            <span class="n">ret</span><span class="p">.</span><span class="nf">cuda</span><span class="p">()</span>

<span class="k">return</span> <span class="nc">Variable</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span></code></pre></figure> <h3 id="results-1">Results</h3> <p>I again split the dataset with a 70/30 train-test split (~95k training names, ~40.6k testing names). The best testing accuracy I was able to achieve was around <strong>75.4% accuracy</strong>. I did not spend much time tweaking hyper-parameters for better results.</p> <h2 id="dataset--name2genderdata">Dataset — <a href="https://github.com/ellisbrown/name2gender/tree/master/data">name2gender/data/</a></h2> <p>I have extended NLTK’s names corpus with many more datasets representing various cultures into a large dataset (~135k instances) of gender-labeled first names, which is available on my repository. See <a href="https://github.com/ellisbrown/name2gender/blob/master/data/dataset.ipynb">data/dataset.ipynb</a> for further information on how I pulled it together. <em>Note:</em> I did not spend a ton of time going through and pruning this dataset, so it is probably not amazing or particularly clean (I would greatly appreciate any PR’s if anyone cares or has the time!).</p> <p>Improving / cleaning this dataset would likely be the most impactful improvement initially. Additionally, using a dataset of only names from a single culture would likely be much better at predicting names in that culture.</p> <hr/> <h2 id="disclaimer">Disclaimer</h2> <p>It is worthy to acknowledge that there are many names, such as my own (Ellis), that are about equally common among both genders. Datasets containing discrete labels, as opposed to frequency of occurrence in the world, were much easier to come across, and so I have only taken into consideration the binary classification of names given by these datasets. A more robust approach would incorporate the frequency of occurrence in a population to give a more probabilistic gender prediction. The “Gender-name association scores” approach by Wendy Liu might be a good approach.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">4</a></sup> The presence of gender ambiguous names also limits the best case real-world accuracy that could be achieved by a gender classification system.</p> <p>Furthermore, there are increasing movements being made to recognize more than the traditional binary male and female genders in our society. As these efforts are still in their infancy and there is very little (if any) data containing these expanded gender classifications, I make no attempt to incorporate them into this analysis.</p> <p>I also only take names written in the Latin Alphabet into consideration. Abstracting to entirely language agnostic classification is too formidable a task for the sake of this post.</p> <h2 id="future-work">Future Work</h2> <p>As I touched on above, improving the dataset is definitely the best starting point for improvements. Application of this name to gender classification to variations of first names would be a really useful to anyone who finds first name classification useful. As Wendy Liu puts it:</p> <blockquote> <p>“Nicknames, abbreviations, mangled names, and usernames can frequently contain non-trivial gender cues. Identifying strategies for extracting and using these cues to more accurately infer gender is a promising direction for future work.” <sup id="fnref:3:1" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">4</a></sup></p> </blockquote> <figure class="align-right" style="max-width: 280px"> <img src="/assets/posts/name2gen/freq.png" alt="Freq" style="max-width: 100%" data-zoomable=""/> <figcaption>Name Frequency Scheme</figcaption> <br/> </figure> <p>There is also the possibility of crafting the testing scheme to better represent a real world use case. In my analysis, I treated every name as equally likely to occur. A better real world dataset might include some representation of how frequently a certain name occurs in the world. For example, “John” would have a much higher frequency rating than “Ellis.” This change would affect how the testing results are calculated, and the system as a whole. We would ideally have most of the common first names included in our dataset.</p> <p>For such names, we could simply lookup what our datastore has for the gender of the name. Our predictive system would then only be applied to the set of names that are not common. To test this system setup, we could sort the names by frequency rating, and leave the 30% of names that are least common for the test set.</p> <p><br/> <br/></p> <hr/> <p><br/></p> <h2 id="references">References</h2> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p>Bird, S., Klein, E., and Loper, E. “6.1.1 Gender Identification.” Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit, O’Reilly, 2009, <a href="https://www.nltk.org/book/ch06.html" style="word-wrap:break-word;">https://www.nltk.org/book/ch06.html</a>. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:1:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p> </li> <li id="fn:2" role="doc-endnote"> <p>“Grammatical Gender.” Wikipedia, Wikimedia Foundation, 21 Dec. 2017, <a href="http://en.wikipedia.org/wiki/Grammatical_gender" style="word-wrap:break-word;">http://en.wikipedia.org/wiki/Grammatical_gender</a>. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:4" role="doc-endnote"> <p>Robertson, S. “Classifying Names with a Character-Level RNN.” Classifying Names with a Character-Level RNN, PyTorch Docs, 2017, <a href="http://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html" style="word-wrap:break-word;">http://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html</a>. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:3" role="doc-endnote"> <p>Liu, W., and Ruths, D. “What’s in a Name? Using First Names as Features for Gender Inference in Twitter” AAAI Spring Symposium Series (2013), 21 Dec. 2017, <a href="https://www.semanticscholar.org/paper/What%27s-in-a-Name-Using-First-Names-as-Features-for-Liu-Ruths/b60d04043a60e46670f182b2debb485e9d17ce46?utm_source=direct_link" style="word-wrap:break-word;">link</a>. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:3:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="NLP"/><category term="NLP"/><category term="Classification"/><category term="PyTorch"/><summary type="html"><![CDATA[Accurate prediction of an unknown individual’s gender is desirable for use in marketing, social science, and many other applications in academia and industry. Perhaps the most obvious and telling indicator of a person’s gender is their first name.]]></summary></entry></feed>